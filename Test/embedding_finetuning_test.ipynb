{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(system, user, model_name=\"gpt-3.5-turbo\", max_tokens=20, temperature=1, logprobs=False, top_logprobs=None):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"content\": system, \"role\": \"system\"},\n",
    "            {\"role\": \"user\", \"content\": user}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        logprobs=logprobs,\n",
    "        top_logprobs=top_logprobs\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-93TcLDIpwdmi62U6F7UdUS8zHPSny', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1 + 1 = 2', role='assistant', function_call=None, tool_calls=None))], created=1710615861, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=7, prompt_tokens=22, total_tokens=29))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = 'You are an assistant.'\n",
    "user = '1 + 1 = ?'\n",
    "response = generate_text(system, user)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter, SimpleNodeParser\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "def load_corpus(directory, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files in {directory}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(directory)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in Camel Papers Train\n",
      "Loaded 91 docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59eaac66d6874f1589f45d73dd1b30f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 156 nodes\n",
      "Loading files in Camel Papers Test\n",
      "Loaded 9 docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2491a8988c33443eaaebdbd2f73a6494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 17 nodes\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILES = \"Camel Papers Train\"\n",
    "VAL_FILES = \"Camel Papers Test\"\n",
    "train_nodes = load_corpus(TRAIN_FILES, verbose=True)\n",
    "val_nodes = load_corpus(VAL_FILES, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 CVVO 5JUL 2011Case Report  Rapport de cas\n",
      "Acute respiratory distress syndrome in an alpaca cria\n",
      "KatharineMSimpson,RobertNStreeter,SuzanneGGenova\n",
      "Abstract —  A 7-hour-old alpaca was presented for lethargy and depression. The cria responded favorably to initial \n",
      "treatment but developed acute-onset dyspnea 48 hours later. Acute respiratory distress syndrome was diagnosed \n",
      "by thoracic imaging and blood gas analysis. The cria was successfully treated with corticosteroids and discharged \n",
      "from the hospital.\n",
      "Résumé —  Syndrome de détresse respiratoire aiguë chez un cria alpaga.  Un alpaga âgé de 7 heures a été présenté \n",
      "en raison d’abattement et de dépression. Le cria a réagi favorablement au traitement initial mais a développé une \n",
      "dyspnée d’apparition aiguë 48 heures plus tard. Le syndrome de détresse respiratoire aiguë a été diagnostiqué par imagerie thoracique et gazométrie sanguine. Le cria a été traité avec succès à l’aide de corticostéroïdes et a reçu son \n",
      "congé.\n",
      "(Traduit par Isabelle Vallières)\n",
      "Can Vet J 2011;52:784–787\n",
      "Introduction\n",
      "Acute respiratory distress syndrome, referred to as ARDS, \n",
      "is the manifestation of an intra- or extra-pulmonary insult \n",
      "resulting in an overzealous inflammatory cascade in the lungs. \n",
      "Ultimately, interstitial pulmonary edema develops and is fre -\n",
      "quently fatal. The syndrome was first described in humans but \n",
      "has since been recognized in animals, particularly in companion animals and foals (1,2). Mortality rates vary from up to 60% in humans to almost 100% in small animal species (2). This syn -\n",
      "drome has not been previously reported in a camelid species, but should be included on the list of differential diagnoses for crias with acute onset respiratory distress. Although the prognosis in other species is often guarded, treatment of alpaca crias can \n",
      "have a good outcome.\n",
      "Case description\n",
      "An approximately  7-hour-old 5.2-kg female intact Suri alpaca \n",
      "cria was presented to the Oklahoma State University Boren \n",
      "Veterinary Medical Teaching Hospital with the complaint of \n",
      "being hypothermic, lethargic, and unable to stand and nurse. \n",
      "By the owners’ records the cria was at least 1 wk premature. The primiparous dam had delivered the cria unassisted and unobserved. Upon finding the cria, the owners determined that she was hypothermic (actual temperature not reported) and attempted to warm her with blankets, a heater, and warm water baths. Attempts were made to milk out the dam, but only 5 mL of colostrum were obtained and were fed to the cria along with \n",
      "60 mL of milk replacer, which the cria suckled readily from a \n",
      "bottle. However, lethargy and inability to rise persisted and the cria was admitted to the hospital the following morning.\n",
      "On presentation, the cria was obtunded and unable to main -\n",
      "tain sternal recumbency. Rectal temperature was 36.7°C (98°F) \n",
      "[reference interval (RI): 37.8 to 38.9°C (100 to 102°F)], and \n",
      "the pulse was 104 beats/min (RI: 60 to 90 beats/min) with no detectable murmurs or arrhythmias. The respiratory rate was 60 breaths/min (RI: 10 to 30 breaths/min) with no auscultable abnormalities bilaterally, although mild nostril flaring was noted. \n",
      "Mucous membranes were hyperemic with a capillary refill time \n",
      "of , 2 s. The incisors were not erupted, and both ears were \n",
      "curled at the tips. Moderate scleral injection and mild hyphema were present bilaterally. A bilateral nasal oxygen cannula was \n",
      "immediately placed and oxygen administered at 2.5 L/min. A \n",
      "20-gauge double lumen J-wire catheter was aseptically placed in the left jugular vein and blood was drawn for aerobic culture, complete blood (cell) count (CBC), and chemistry panel.\n"
     ]
    }
   ],
   "source": [
    "print(val_nodes[0].text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a Fine-tuning Dataset\n",
    "\n",
    "Using the nodes to construct the dataset utilizing OpenAI's `gpt-3.5-turbo`.\n",
    "\n",
    "The basic idea:\n",
    "\n",
    "1. We look at a node\n",
    "2. We generate a question that could be answered by that node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [03:52<00:00,  1.49s/it]\n",
      "100%|██████████| 17/17 [00:23<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "train_dataset = generate_question_context_pairs(\n",
    "    llm=llm, nodes=train_nodes\n",
    ")\n",
    "\n",
    "val_dataset = generate_question_context_pairs(\n",
    "    llm=llm, nodes=val_nodes\n",
    ")\n",
    "\n",
    "train_dataset.save_json(\"train_dataset.json\")\n",
    "val_dataset.save_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning `BAAI/bge-small-en-v1.5`\n",
    "\n",
    "Use  [`bge-small-en-v1.5`](https://huggingface.co/BAAI/bge-small-en-v1.5) as the backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
    "\n",
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"BAAI/bge-small-en-v1.5\", \n",
    "    model_output_path=\"my_model_v1\",\n",
    "    val_dataset=val_dataset, \n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d04a3921a094abd97c7fb9ea7ebbf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5554ac897345bfae09526dd7920aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bad90ff8c624453a44e190d088f4394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_embedding_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"model_name\": \"my_model_v1\", \"embed_batch_size\": 10, \"tokenizer_name\": \"my_model_v1\", \"max_length\": 512, \"pooling\": \"cls\", \"normalize\": true, \"query_instruction\": null, \"text_instruction\": null, \"cache_folder\": null, \"class_name\": \"HuggingFaceEmbedding\"}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_embedding_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"my_model_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "def evaluate_st(\n",
    "    dataset,\n",
    "    model_id,\n",
    "    name,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
    "    model = SentenceTransformer(model_id)\n",
    "    output_path = \"results/\"\n",
    "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
    "    return evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6446428571428571"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"BAAI/bge-small-en-v1.5\", name=\"bge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7118814192343603"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"my_model_v1\", name=\"finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
